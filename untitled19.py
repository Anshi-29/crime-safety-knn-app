# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IJULLpKOfoynUruTohbAPwmzHkz1ubW3
"""

import numpy as np
import matplotlib.pyplot as plt
from collections import Counter

class KNeighborsClassifier:
    def __init__(self, n_neighbors=3):
        self.n_neighbors = n_neighbors

    def fit(self, X, y):
        self.X_train = X
        self.y_train = y

    def predict(self, X):
        predictions = [self._predict(x) for x in X]
        return np.array(predictions)

    def _predict(self, x):
        # Compute distances between x and all examples in the training set
        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]

        # Get indices of the k nearest neighbors
        k_indices = np.argsort(distances)[:self.n_neighbors]

        # Get the labels of these neighbors
        k_nearest_labels = [self.y_train[i] for i in k_indices]

        # Return the most common class label
        most_common = Counter(k_nearest_labels).most_common(1)
        return most_common[0][0]

# Example usage matching your code
X_train = np.array([
    [150, 7],
    [170, 7.5],
    [130, 6],
    [100, 6.5],
    [130, 8]
])

y_train = np.array([0, 0, 1, 1, 0])
X_new = np.array([[155, 6.7]])

# Create and train the classifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

# Make prediction
y_pred = knn.predict(X_new)
predicted_label = 'Apple' if y_pred[0] == 0 else 'Orange'

# Plotting the results
plt.figure(figsize=(8, 6))

for i, label in enumerate(y_train):
    color = 'red' if label == 0 else 'orange'
    marker = 'o' if label == 0 else 's'
    plt.scatter(X_train[i, 0], X_train[i, 1], color=color, marker=marker, s=100,
                label='Apple' if label == 0 else 'Orange')

# Remove duplicate labels
handles, labels = plt.gca().get_legend_handles_labels()
by_label = dict(zip(labels, handles))
plt.legend(by_label.values(), by_label.keys())

plt.scatter(X_new[0, 0], X_new[0, 1], color='blue', marker='*', s=200,
            label=f'New Fruit (Predicted: {predicted_label})')
plt.xlabel("Weight (g)")
plt.ylabel("Other Feature")
plt.title("KNN Classification (k=3)")
plt.legend()
plt.show()

print(f"Predicted class for new fruit: {predicted_label}")

import numpy as np
from collections import Counter

class SimpleKNN:
    def __init__(self, k=3):
        self.k = k

    def fit(self, X, y):
        self.X_train = X
        self.y_train = y

    def predict(self, X):
        return np.array([self._predict(x) for x in X])

    def _predict(self, x):
        # Calculate distances to all training points
        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]

        # Get indices of k nearest neighbors
        k_indices = np.argsort(distances)[:self.k]

        # Get labels of nearest neighbors
        k_labels = [self.y_train[i] for i in k_indices]

        # Return majority vote
        most_common = Counter(k_labels).most_common(1)
        return most_common[0][0]

# Training data (features: [weight, some_other_feature], labels: 0=Apple, 1=Orange)
X_train = np.array([
    [150, 7],
    [170, 7.5],
    [130, 6],
    [100, 6.5],
    [130, 8]
])
y_train = np.array([0, 0, 1, 1, 0])

# New fruit to classify
X_new = np.array([[155, 6.7]])

# Create and train KNN
knn = SimpleKNN(k=3)
knn.fit(X_train, y_train)

# Make prediction
prediction = knn.predict(X_new)
fruit = "Apple" if prediction[0] == 0 else "Orange"

# Display results
print("Training Data:")
for features, label in zip(X_train, y_train):
    print(f"- Features: {features}, Label: {'Apple' if label == 0 else 'Orange'}")

print(f"\nNew Fruit Features: {X_new[0]}")
print(f"\nKNN Prediction Process (k=3):")
print("1. Calculate distances to all training points:")

distances = [np.sqrt(np.sum((X_new[0] - x_train)**2)) for x_train in X_train]
for i, dist in enumerate(distances):
    print(f"   - Distance to training point {i+1}: {dist:.2f}")

print("\n2. Select 3 nearest neighbors:")
sorted_indices = np.argsort(distances)[:3]
for i, idx in enumerate(sorted_indices):
    print(f"   - Neighbor {i+1}: Features {X_train[idx]}, Label: {'Apple' if y_train[idx] == 0 else 'Orange'}")

print("\n3. Majority vote:")
neighbor_labels = [y_train[idx] for idx in sorted_indices]
label_counts = Counter(neighbor_labels)
for label, count in label_counts.items():
    print(f"   - {'Apple' if label == 0 else 'Orange'}: {count} votes")

print(f"\nFinal Prediction: {fruit}")

import numpy as np
from collections import Counter

class KNN:
    def __init__(self, k=3):
        self.k = k

    def fit(self, X, y):
        self.X_train = X  # Features: [Size (m¬≤), Price ($)]
        self.y_train = y  # Labels: House types

    def predict(self, X):
        return np.array([self._predict(x) for x in X])

    def _predict(self, x):
        # Calculate Euclidean distances
        distances = [np.sqrt((x[0] - x_train[0])**2 + (x[1] - x_train[1])**2)
                    for x_train in self.X_train]
        # Get k-nearest neighbors' labels
        k_indices = np.argsort(distances)[:self.k]
        k_labels = [self.y_train[i] for i in k_indices]
        # Majority vote
        most_common = Counter(k_labels).most_common(1)
        return most_common[0][0]

# Training Data: [Size (m¬≤), Price ($)], House Type
X_train = np.array([
    [120, 500000],  # Apartment
    [200, 800000],  # Villa
    [80, 300000],   # Studio
    [150, 600000],  # Apartment
    [250, 900000],  # Villa
    [95, 350000]    # Studio
])
y_train = np.array(['Apartment', 'Villa', 'Studio', 'Apartment', 'Villa', 'Studio'])

# Test Data: Predict for 90 m¬≤, $450,000
X_test = np.array([[90, 450000]])

# Initialize and train KNN
knn = KNN(k=3)
knn.fit(X_train, y_train)

# Predict
prediction = knn.predict(X_test)
print(f"Predicted house type for 90 m¬≤ at $450,000: {prediction[0]}")

# Step-by-step explanation
print("\nPrediction Process (k=3) ")
distances = [np.sqrt((X_test[0][0] - x[0])**2 + (X_test[0][1] - x[1])**2) for x in X_train]
print("1. Distances to training points:")
for i, (features, label) in enumerate(zip(X_train, y_train)):
    print(f"   - {features} ({label}): {distances[i]:.2f}")

k_indices = np.argsort(distances)[:3]
print("\n2. Nearest neighbors (k=3):")
for idx in k_indices:
    print(f"   - {X_train[idx]} ({y_train[idx]})")

print("\n3. Majority vote:")
neighbor_labels = [y_train[i] for i in k_indices]
votes = Counter(neighbor_labels)
for label, count in votes.items():
    print(f"   - {label}: {count} vote(s)")

# Visualization
plt.figure(figsize=(10, 6))

# 1. Plot training points
for row, label in zip(X_train, y_train):
    plt.scatter(row[0], row[1], color=colors[label], s=100,
                label=f'{label}' if label not in plt.gca().get_legend_handles_labels()[1] else "",
                edgecolor='black')

# 2. Plot test house
plt.scatter(X_test[0,0], X_test[0,1], color='red', marker='*', s=200,
            label=f'Test House (Predicted: {prediction})')

# 3. Highlight nearest neighbors
distances = [np.sqrt((X_test[0,0]-x[0])**2 + (X_test[0,1]-x[1])**2) for x in X_train]
k_indices = np.argsort(distances)[:3]
for i in k_indices:
    plt.plot([X_test[0,0], X_train[i,0]], [X_test[0,1], X_train[i,1]],
             'gray', linestyle='--', alpha=0.5)

# Formatting
plt.title('House Type Prediction (KNN)', fontsize=14)
plt.xlabel('Size (m¬≤)', fontsize=12)
plt.ylabel('Price ($)', fontsize=12)
plt.grid(True, alpha=0.2)
plt.legend()

# Add distance annotations
# Change the loop to iterate through rows and use indexing on the row
for i, row in enumerate(X_train):
    dist = distances[i]
    # Access elements using row[0] and row[1]
    plt.annotate(f'{dist/1000:.0f}k', (row[0]+2, row[1]-20000), fontsize=8)

plt.show()

print(f"\nPredicted house type for 90 m¬≤ at $450,000: {prediction}")

!pip install gradio

import pandas as pd

data = {
    "City": ["Delhi", "Mumbai", "Jaipur", "Kanpur", "Lucknow", "Pune", "Bangalore", "Hyderabad"],
    "Theft": [75, 30, 20, 60, 50, 25, 35, 45],
    "Assault": [45, 20, 15, 40, 38, 18, 25, 30],
    "Robbery": [50, 10, 5, 30, 28, 8, 15, 20],
    "Fraud": [40, 15, 10, 35, 25, 12, 20, 22],
    "Murder": [20, 5, 2, 18, 15, 4, 7, 10],
    "SafeLevel": ["Unsafe", "Safe", "Safe", "Moderate", "Moderate", "Safe", "Moderate", "Moderate"]
}

df = pd.DataFrame(data)
df.head()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

X = df[["Theft", "Assault", "Robbery", "Fraud", "Murder"]]
y = df["SafeLevel"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

import numpy as np

def predict_safety(theft, assault, robbery, fraud, murder, time_of_day):
    input_df = pd.DataFrame(np.array([[theft, assault, robbery, fraud, murder]]),
                            columns=["Theft", "Assault", "Robbery", "Fraud", "Murder"])
    features = scaler.transform(input_df)
    prediction = knn.predict(features)[0]

    time_factor = "0.9" if time_of_day == "Day" else "1.2"
    message = (
        f"üîç Safety Level: {prediction}\n"
        f"‚è∞ Time Factor: {time_of_day} (x{time_factor} risk)\n"
        f"üõ°Ô∏è Safety Tips:\n"
        "‚Ä¢ Stay aware in crowded spaces\n"
        "‚Ä¢ Secure belongings in tourist areas\n"
        "‚Ä¢ Verify official personnel identity"
    )
    return message

import gradio as gr

interface = gr.Interface(
    fn=predict_safety,
    inputs=[
        gr.Slider(0, 100, label="Theft"),
        gr.Slider(0, 100, label="Assault"),
        gr.Slider(0, 100, label="Robbery"),
        gr.Slider(0, 100, label="Fraud"),
        gr.Slider(0, 100, label="Murder"),
        gr.Radio(["Day", "Night"], label="Time of Day")
    ],
    outputs=gr.Textbox(label="Safety Level Prediction"),
    title="üö® AI Crime Predictor & Area Safety Recommender (KNN)",
    description="Enter crime statistics to check area safety level."
)

interface.launch(share=True)